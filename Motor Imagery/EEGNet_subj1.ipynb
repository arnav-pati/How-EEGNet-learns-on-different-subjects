{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deepak/learning_project/student'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deepak/learning_project/student\n"
     ]
    }
   ],
   "source": [
    "%cd /home/deepak/learning_project/student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboardX in /home/deepak/.local/lib/python3.8/site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in /home/deepak/.local/lib/python3.8/site-packages (from tensorboardX) (1.23.4)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepak/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6704c8c170>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNShot():\n",
    "    def __init__(self, root, data_npy, train_subj, test_subj, batchsz, n_way, k_shot, k_query, eeg_shape, num_trials, batchst=1):\n",
    "        self.num_trials = num_trials\n",
    "        self.batchsz = {\"train\": batchsz, \"test\": batchst}\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.eeg_shape = eeg_shape\n",
    "        self.root = root\n",
    "        self.data_npy = data_npy\n",
    "        self.train_subj = train_subj\n",
    "        self.test_subj = test_subj\n",
    "        self.subj = {\"train\": self.train_subj, \"test\": self.test_subj}\n",
    "\n",
    "    def get_data(self, mode, subj, cls, trial):\n",
    "        return np.load(os.path.join(self.root, self.data_npy+'_'+'train', f\"s{subj}_c{cls}_t{trial}.npy\"))\n",
    "        # return raw - raw.mean(axis=0)\n",
    "\n",
    "    def get_batch(self, mode):\n",
    "        setsz = self.k_shot * self.n_way\n",
    "        querysz = self.k_query * self.n_way\n",
    "        num_subj = self.subj[mode]\n",
    "\n",
    "        support_x = np.zeros((self.batchsz[mode], setsz) + self.eeg_shape)\n",
    "        support_y = np.zeros((self.batchsz[mode], setsz), dtype=int)\n",
    "        query_x = np.zeros((self.batchsz[mode], querysz) + self.eeg_shape)\n",
    "        query_y = np.zeros((self.batchsz[mode], querysz), dtype=int)\n",
    "\n",
    "        selected_tasks = np.random.choice(num_subj, self.batchsz[mode], False)\n",
    "        for i, cur_task in enumerate(selected_tasks):\n",
    "            shuffle_idx = np.arange(self.n_way)\n",
    "            np.random.shuffle(shuffle_idx)\n",
    "            shuffle_idx_test = np.arange(self.n_way)\n",
    "            np.random.shuffle(shuffle_idx_test)\n",
    "\n",
    "            for j in range(self.n_way):\n",
    "                selected_data = np.random.choice(self.num_trials, self.k_shot + self.k_query, False)\n",
    "\n",
    "                for offset, eeg in enumerate(selected_data[:self.k_shot]):\n",
    "                    support_x[i, shuffle_idx[j] * self.k_shot + offset, ...] = self.get_data(mode, cur_task, j, eeg)\n",
    "                    support_y[i, shuffle_idx[j] * self.k_shot + offset] = j\n",
    "\n",
    "                for offset, eeg in enumerate(selected_data[self.k_shot:]):\n",
    "                    query_x[i, shuffle_idx_test[j] * self.k_query + offset, ...] = self.get_data(mode, cur_task, j, eeg)\n",
    "                    query_y[i, shuffle_idx_test[j] * self.k_query + offset] = j\n",
    "\n",
    "        return support_x, support_y, query_x, query_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, db, mode, k_shot, k_query) -> None:\n",
    "        super().__init__()\n",
    "        # self.data = data\n",
    "        self.db = db\n",
    "        self.mode = mode\n",
    "        self.shape = (len(db.subj[mode]), db.n_way, db.num_trials) + db.eeg_shape\n",
    "        self.n_way = self.shape[1]\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.out_shape = (self.n_way * self.k_shot,) + self.shape[-2:]\n",
    "        self.out_shape_query = (self.n_way * self.k_query,) + self.shape[-2:]\n",
    "        self.shuffle_idx = np.zeros(self.shape[:3], dtype=int)\n",
    "        for p in range(self.shape[0]):\n",
    "            for q in range(self.shape[1]):\n",
    "                idx_range = np.arange(self.shape[2])\n",
    "                np.random.shuffle(idx_range)\n",
    "                self.shuffle_idx[p, q, ...] = idx_range\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0] * (self.shape[2] // (self.k_shot + self.k_query))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx2 = (self.k_shot + self.k_query) * (idx // self.shape[0])\n",
    "        idx0 = idx % self.shape[0]\n",
    "\n",
    "        support_x = np.zeros(self.out_shape)\n",
    "        support_y = np.zeros(self.out_shape[:1], dtype=int)\n",
    "        query_x = np.zeros(self.out_shape_query)\n",
    "        query_y = np.zeros(self.out_shape_query[:1], dtype=int)\n",
    "\n",
    "        for j in range(self.n_way):\n",
    "            # support_x[(j*self.k_shot):((j+1)*self.k_shot), ...] = self.data[idx0][j][self.shuffle_idx[idx0, j, idx2:idx2+self.k_shot]]\n",
    "            for v in range(self.k_shot):\n",
    "                support_x[(j*self.k_shot) + v, ...] = self.db.get_data(self.mode, self.db.subj[self.mode][idx0], j, self.shuffle_idx[idx0, j, idx2+v])\n",
    "            support_y[(j*self.k_shot):((j+1)*self.k_shot)] = j\n",
    "\n",
    "            # query_x[(j*self.k_query):((j+1)*self.k_query), ...] = self.data[idx0][j][self.shuffle_idx[idx0, j, idx2+self.k_shot:idx2+self.k_shot+self.k_query]]\n",
    "            for v in range(self.k_query):\n",
    "                query_x[(j*self.k_query) + v, ...] = self.db.get_data(self.mode, self.db.subj[self.mode][idx0], j, self.shuffle_idx[idx0, j, idx2+self.k_shot+v])\n",
    "            query_y[(j*self.k_query):((j+1)*self.k_query)] = j\n",
    "\n",
    "        return support_x, support_y, query_x, query_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroDataset(Dataset):\n",
    "    def __init__(self, db, mode, k_shot, k_query, subj) -> None:\n",
    "        super().__init__()\n",
    "        # self.data = data\n",
    "        self.db = db\n",
    "        self.mode = mode\n",
    "        self.subj = subj\n",
    "        self.shape = (1, db.n_way, db.num_trials) + db.eeg_shape\n",
    "        self.n_way = self.shape[1]\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.out_shape = (self.n_way * self.k_shot,) + self.shape[-2:]\n",
    "        self.out_shape_query = (self.n_way * self.k_query,) + self.shape[-2:]\n",
    "        self.shuffle_idx = np.zeros(self.shape[:3], dtype=int)\n",
    "        for p in range(self.shape[0]):\n",
    "            for q in range(self.shape[1]):\n",
    "                idx_range = np.arange(self.shape[2])\n",
    "                np.random.shuffle(idx_range)\n",
    "                self.shuffle_idx[p, q, ...] = idx_range\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0] * (self.shape[2] // (self.k_shot + self.k_query))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx2 = (self.k_shot + self.k_query) * (idx // self.shape[0])\n",
    "        idx0 = idx % self.shape[0]\n",
    "\n",
    "        support_x = np.zeros(self.out_shape)\n",
    "        support_y = np.zeros(self.out_shape[:1], dtype=int)\n",
    "        query_x = np.zeros(self.out_shape_query)\n",
    "        query_y = np.zeros(self.out_shape_query[:1], dtype=int)\n",
    "\n",
    "        for j in range(self.n_way):\n",
    "            # support_x[(j*self.k_shot):((j+1)*self.k_shot), ...] = self.data[idx0][j][self.shuffle_idx[idx0, j, idx2:idx2+self.k_shot]]\n",
    "            for v in range(self.k_shot):\n",
    "                support_x[(j*self.k_shot) + v, ...] = self.db.get_data(self.mode, self.subj, j, self.shuffle_idx[idx0, j, idx2+v])\n",
    "            support_y[(j*self.k_shot):((j+1)*self.k_shot)] = j\n",
    "\n",
    "            # query_x[(j*self.k_query):((j+1)*self.k_query), ...] = self.data[idx0][j][self.shuffle_idx[idx0, j, idx2+self.k_shot:idx2+self.k_shot+self.k_query]]\n",
    "            for v in range(self.k_query):\n",
    "                query_x[(j*self.k_query) + v, ...] = self.db.get_data(self.mode, self.subj, j, self.shuffle_idx[idx0, j, idx2+self.k_shot+v])\n",
    "            query_y[(j*self.k_query):((j+1)*self.k_query)] = j\n",
    "\n",
    "        return support_x, support_y, query_x, query_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reptile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    '''\n",
    "    It stores a specific nn.Module class\n",
    "    '''\n",
    "\n",
    "    def __init__(self, net_class, *args) -> None:\n",
    "        '''\n",
    "        net_class is a class, not an instance\n",
    "        args: the parameters for net_class\n",
    "        '''\n",
    "        super(Learner, self).__init__()\n",
    "        assert net_class.__class__ == type\n",
    "\n",
    "        self.net = net_class(*args).to(DEVICE)\n",
    "        self.net_pi = net_class(*args).to(DEVICE)\n",
    "        self.learner_lr = 0.1\n",
    "        self.optimizer = optim.SGD(self.net_pi.parameters(), self.learner_lr)\n",
    "\n",
    "    def parameters(self):\n",
    "        '''\n",
    "        ignore self.net_pi.parameters()\n",
    "        '''\n",
    "        return self.net.parameters()\n",
    "\n",
    "    def update_pi(self):\n",
    "        for m_from, m_to in zip(self.net.modules(), self.net_pi.modules()):\n",
    "            if isinstance(m_to, nn.Linear) or isinstance(m_to, nn.Conv2d) or isinstance(m_to, nn.BatchNorm2d):\n",
    "                m_to.weight.data = m_from.weight.data.clone()\n",
    "                if m_to.bias is not None:\n",
    "                    m_to.bias.data = m_from.bias.data.clone()\n",
    "\n",
    "    def forward(self, support_x, support_y, query_x, query_y, num_updates, testing=False):\n",
    "        self.update_pi()\n",
    "        if testing:\n",
    "            self.net_pi.freeze()\n",
    "        for i in range(num_updates):\n",
    "            loss, pred = self.net_pi(support_x, support_y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if testing:\n",
    "            self.net_pi.unfreeze()\n",
    "        loss, pred = self.net_pi(query_x, query_y)\n",
    "        indices = torch.argmax(pred, dim=1)\n",
    "        correct = torch.eq(indices, query_y).sum().item()\n",
    "        acc = correct / query_y.size(0)\n",
    "\n",
    "        grads_pi = autograd.grad(loss, self.net_pi.parameters(), create_graph=True)\n",
    "        return loss, grads_pi, acc\n",
    "\n",
    "    def net_forward(self, support_x, support_y):\n",
    "        loss, pred = self.net(support_x, support_y)\n",
    "        return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    def __init__(self, net_class, net_class_args, n_way, k_shot, meta_batchesz, beta, num_updates, num_updates_test) -> None:\n",
    "        super(MetaLearner, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.meta_batchesz = meta_batchesz\n",
    "        self.beta = beta\n",
    "        self.num_updates = num_updates\n",
    "        self.num_updates_test = num_updates_test\n",
    "\n",
    "        self.learner = Learner(net_class, *net_class_args)\n",
    "        self.optimizer = optim.Adam(self.learner.parameters(), lr=beta)\n",
    "\n",
    "    def write_grads(self, dummy_loss, sum_grads_pi):\n",
    "        hooks = []\n",
    "        for i, v in enumerate(self.learner.parameters()):\n",
    "            def closure():\n",
    "                ii = i\n",
    "                return lambda grad : sum_grads_pi[ii]\n",
    "            # h = v.register_hook(closure())\n",
    "            hooks.append(v.register_hook(closure()))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        dummy_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "    def forward(self, support_x, support_y, query_x, query_y):\n",
    "        sum_grads_pi = None\n",
    "        meta_batchesz = support_y.size(0)\n",
    "\n",
    "        accs = []\n",
    "        for i in range(meta_batchesz):\n",
    "            _, grad_pi, episode_acc = self.learner(support_x[i], support_y[i], query_x[i], query_y[i], self.num_updates)\n",
    "            accs.append(episode_acc)\n",
    "            if sum_grads_pi is None:\n",
    "                sum_grads_pi = grad_pi\n",
    "            else:\n",
    "                sum_grads_pi = [torch.add(p, q) for p, q in zip(sum_grads_pi, grad_pi)]\n",
    "        dummy_loss, _ = self.learner.net_forward(support_x[0], support_y[0])\n",
    "        self.write_grads(dummy_loss, sum_grads_pi)\n",
    "\n",
    "        return accs\n",
    "\n",
    "    def pred(self, support_x, support_y, query_x, query_y):\n",
    "        meta_batchesz = support_y.size(0)\n",
    "        accs = []\n",
    "        for i in range(meta_batchesz):\n",
    "            _, _, episode_acc = self.learner(support_x[i], support_y[i], query_x[i], query_y[i], self.num_updates_test, testing=True)\n",
    "            accs.append(episode_acc)\n",
    "        return np.array(accs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, nb_classes, Chans = 22, Samples = 1001,\n",
    "                 dropoutRate = 0.5, kernLength = 64, F1 = 8,\n",
    "                 D = 2, F2 = 16, norm_rate = 0.25) -> None:\n",
    "        super().__init__()\n",
    "        self.device = DEVICE\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernLength), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.Conv2d(F1, F1 * D, (Chans, 1), groups=F1, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(dropoutRate)\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(F2, F2, (1, 16), padding='same', bias=False),\n",
    "            nn.Conv2d(F2, F2, 1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(dropoutRate)\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        self.block_weights = ['block1.0.weight', 'block1.1.weight', 'block1.1.bias', 'block1.2.weight', 'block1.3.weight', 'block1.3.bias', 'block2.0.weight', 'block2.1.weight', 'block2.2.weight', 'block2.2.bias']\n",
    "\n",
    "        self.classifier_input = 16 * ((Samples // 4) // 8)\n",
    "        self.classifier_hidden = int((self.classifier_input * nb_classes) ** 0.5)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.classifier_input, self.classifier_hidden),\n",
    "            nn.Linear(self.classifier_hidden, nb_classes)\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        x = self.block1(torch.unsqueeze(x, 1))\n",
    "        x = self.block2(x)\n",
    "        pred = self.classifier(x)\n",
    "\n",
    "        loss = self.criterion(pred, target)\n",
    "        return loss, pred\n",
    "\n",
    "    def freeze(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in self.block_weights:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def unfreeze(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in self.block_weights:\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_train(db, meta, iterations):\n",
    "    tb = SummaryWriter('runs')\n",
    "    for episode_num in range(iterations):\n",
    "        support_x, support_y, query_x, query_y = db.get_batch('train')\n",
    "        support_x = Variable( torch.from_numpy(support_x).float()).to(DEVICE)\n",
    "        query_x = Variable( torch.from_numpy(query_x).float()).to(DEVICE)\n",
    "        support_y = Variable(torch.from_numpy(support_y).long()).to(DEVICE)\n",
    "        query_y = Variable(torch.from_numpy(query_y).long()).to(DEVICE)\n",
    "\n",
    "        accs = meta(support_x, support_y, query_x, query_y)\n",
    "        train_acc = 100 * np.array(accs).mean()\n",
    "\n",
    "        if episode_num % 50 == 0:\n",
    "            test_accs = []\n",
    "            for i in range(min(episode_num // 5000 + 3, 10)):\n",
    "                support_x, support_y, query_x, query_y = db.get_batch('test')\n",
    "                support_x = Variable( torch.from_numpy(support_x).float()).to(DEVICE)\n",
    "                query_x = Variable( torch.from_numpy(query_x).float()).to(DEVICE)\n",
    "                support_y = Variable(torch.from_numpy(support_y).long()).to(DEVICE)\n",
    "                query_y = Variable(torch.from_numpy(query_y).long()).to(DEVICE)\n",
    "\n",
    "                test_acc = meta.pred(support_x, support_y, query_x, query_y)\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "            test_acc = 100 * np.array(test_accs).mean()\n",
    "            print('episode:', episode_num, '\\tfinetune acc:%.6f' % train_acc, '\\t\\ttest acc:%.6f' % test_acc)\n",
    "            tb.add_scalar('test-acc', test_acc)\n",
    "            tb.add_scalar('finetune-acc', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, epochs):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    for epoch in range(epochs):\n",
    "        accs = []\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        for support_x, support_y, query_x, query_y in tqdm(train_loader):\n",
    "            support_x = Variable(support_x[0].float()).to(DEVICE)\n",
    "            query_x = Variable(query_x[0].float()).to(DEVICE)\n",
    "            support_y = Variable(support_y[0].long()).to(DEVICE)\n",
    "            query_y = Variable(query_y[0].long()).to(DEVICE)\n",
    "\n",
    "            net.train()\n",
    "            loss, pred = net(support_x, support_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            net.eval()\n",
    "            loss, pred = net(query_x, query_y)\n",
    "            val_loss.append(loss.item())\n",
    "            indices = torch.argmax(pred, dim=1)\n",
    "            correct = torch.eq(indices, query_y).sum().item()\n",
    "            acc = correct / query_y.size(0)\n",
    "            accs.append(acc)\n",
    "        train_loss = np.array(train_loss).mean()\n",
    "        train_log.append(train_loss)\n",
    "        val_loss = np.array(val_loss).mean()\n",
    "        val_log.append(val_loss)\n",
    "        accuracy = 100 * np.array(accs).mean()\n",
    "        print(f'Epoch {epoch+1}:', '\\tvalidation acc: %.6f' % accuracy, '\\tvalidation loss: %.6f' % val_loss, '\\ttrain loss: %.6f' % train_loss)\n",
    "    plt.plot(train_log)\n",
    "    plt.plot(val_log)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(learner, db, min_updates_test=5, max_updates_test=150):\n",
    "    test_loader = DataLoader(\n",
    "        dataset = CustomDataset(db, \"test\", k_shot=0, k_query=4),\n",
    "        batch_size = 1\n",
    "    )\n",
    "    accs = []\n",
    "    for support_x, support_y, query_x, query_y in test_loader:\n",
    "        support_x = Variable(support_x[0].float()).to(DEVICE)\n",
    "        query_x = Variable(query_x[0].float()).to(DEVICE)\n",
    "        support_y = Variable(support_y[0].long()).to(DEVICE)\n",
    "        query_y = Variable(query_y[0].long()).to(DEVICE)\n",
    "        _, _, episode_acc = learner(support_x, support_y, query_x, query_y, 0, testing=True)\n",
    "        accs.append(episode_acc)\n",
    "    accs = 100 * np.array(accs)\n",
    "\n",
    "    results = [{\"mean\":accs.mean(), \"std\":accs.std(), \"num_upd\":0}]\n",
    "    print(f\"{0}-shot accuracy: \\tmean: {results[0]['mean']:.6f}{'%'}\\tstd: {results[0]['std']:.6f}{'%'}\")\n",
    "\n",
    "    for K in range(1, 11):\n",
    "        dct = {\"mean\":0, \"std\":0, \"num_upd\":0}\n",
    "        for num_updates_test in tqdm(range(min_updates_test, max_updates_test, 2)):\n",
    "            test_loader = DataLoader(\n",
    "                dataset = CustomDataset(db, \"test\", k_shot=K, k_query=4),\n",
    "                batch_size = 1\n",
    "            )\n",
    "            accs = []\n",
    "            for support_x, support_y, query_x, query_y in test_loader:\n",
    "                support_x = Variable(support_x[0].float()).to(DEVICE)\n",
    "                query_x = Variable(query_x[0].float()).to(DEVICE)\n",
    "                support_y = Variable(support_y[0].long()).to(DEVICE)\n",
    "                query_y = Variable(query_y[0].long()).to(DEVICE)\n",
    "                _, _, episode_acc = learner(support_x, support_y, query_x, query_y, num_updates_test, testing=True)\n",
    "                accs.append(episode_acc)\n",
    "            accs = 100 * np.array(accs)\n",
    "            if accs.mean() > dct[\"mean\"]:\n",
    "                dct[\"mean\"] = accs.mean()\n",
    "                dct[\"std\"] = accs.std()\n",
    "                dct[\"num_upd\"] = num_updates_test\n",
    "\n",
    "        results.append(dct)\n",
    "        print(f\"{K}-shot accuracy: \\tmean: {dct['mean']:.6f}{'%'}\\tstd: {dct['std']:.6f}{'%'}\\tafter {dct['num_upd']} updates\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate0(learner, db):\n",
    "    for subj in db.subj['train']:\n",
    "        test_loader = DataLoader(\n",
    "            dataset = ZeroDataset(db, \"train\", k_shot=0, k_query=4, subj=subj),\n",
    "            batch_size = 1\n",
    "        )\n",
    "        accs = []\n",
    "        for support_x, support_y, query_x, query_y in test_loader:\n",
    "            support_x = Variable(support_x[0].float()).to(DEVICE)\n",
    "            query_x = Variable(query_x[0].float()).to(DEVICE)\n",
    "            support_y = Variable(support_y[0].long()).to(DEVICE)\n",
    "            query_y = Variable(query_y[0].long()).to(DEVICE)\n",
    "            _, _, episode_acc = learner(support_x, support_y, query_x, query_y, 0, testing=True)\n",
    "            accs.append(episode_acc)\n",
    "        accs = 100 * np.array(accs)\n",
    "\n",
    "        results = [{\"mean\":accs.mean(), \"std\":accs.std(), \"num_upd\":0}]\n",
    "        print(f\"{0}-shot accuracy on subject {subj}: \\tmean: {results[0]['mean']:.6f}{'%'}\\tstd: {results[0]['std']:.6f}{'%'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bciiv2a(model, iterations=30000, epochs=100, Reptile=True):\n",
    "    root = ''\n",
    "    data_npy = 'bciiv2a'\n",
    "    # dataset = BNCI2014001()\n",
    "    meta_batchsz = 5\n",
    "    n_way = 4\n",
    "    k_shot = 4\n",
    "    k_query = k_shot\n",
    "\n",
    "    meta_lr = 1e-3\n",
    "    num_updates = 2\n",
    "    num_updates_test = 10\n",
    "\n",
    "    # fmin, fmax = 4, 32\n",
    "    # raw = dataset.get_data(subjects=[1])[1]['session_T']['run_1']\n",
    "    # dataset_channels = raw.pick_types(eeg=True).ch_names\n",
    "    # sfreq = 250.\n",
    "    # prgm_MI_classes = MotorImagery(n_classes=4, channels=dataset_channels, resample=sfreq, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    i = 1\n",
    "    train_subj = list(range(1, i)) + list(range(i+1, 10))\n",
    "    test_subj = [i]\n",
    "\n",
    "    db = DataNShot(root, data_npy, train_subj, test_subj, meta_batchsz, n_way, k_shot, k_query, (22, 1001), 144)\n",
    "\n",
    "    if Reptile:\n",
    "        meta = MetaLearner(model, (4, 22, 1001), n_way=n_way, k_shot=k_shot, meta_batchesz=meta_batchsz, beta=meta_lr, num_updates=num_updates, num_updates_test=num_updates_test).to(DEVICE)\n",
    "        meta_train(db, meta, iterations)\n",
    "        return meta.learner, db\n",
    "    else:\n",
    "        net = model(4, 22, 1001).to(DEVICE)\n",
    "\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(42)\n",
    "        train_loader = DataLoader(\n",
    "            dataset = CustomDataset(db, \"train\", k_shot=k_shot, k_query=1),\n",
    "            batch_size = 1,\n",
    "            shuffle = True,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g\n",
    "        )\n",
    "        train(net, train_loader, epochs)\n",
    "        net_trained = Learner(model, 4, 22, 1001)\n",
    "        net_trained.net = net\n",
    "        return net_trained, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/224 [00:00<?, ?it/s]/home/deepak/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 224/224 [00:06<00:00, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \tvalidation acc: 31.361607 \tvalidation loss: 1.445162 \ttrain loss: 1.324121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: \tvalidation acc: 36.718750 \tvalidation loss: 1.510015 \ttrain loss: 1.243734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: \tvalidation acc: 39.620536 \tvalidation loss: 1.473118 \ttrain loss: 1.195815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: \tvalidation acc: 42.410714 \tvalidation loss: 1.447338 \ttrain loss: 1.173877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: \tvalidation acc: 39.843750 \tvalidation loss: 1.482064 \ttrain loss: 1.151945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: \tvalidation acc: 43.638393 \tvalidation loss: 1.422194 \ttrain loss: 1.130360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: \tvalidation acc: 46.093750 \tvalidation loss: 1.423241 \ttrain loss: 1.105463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: \tvalidation acc: 45.089286 \tvalidation loss: 1.418021 \ttrain loss: 1.084467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: \tvalidation acc: 46.651786 \tvalidation loss: 1.364698 \ttrain loss: 1.072641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:09<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \tvalidation acc: 46.875000 \tvalidation loss: 1.429583 \ttrain loss: 1.059111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:10<00:00, 21.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: \tvalidation acc: 46.986607 \tvalidation loss: 1.427840 \ttrain loss: 1.034897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:10<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: \tvalidation acc: 46.875000 \tvalidation loss: 1.438454 \ttrain loss: 1.033305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:10<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: \tvalidation acc: 49.107143 \tvalidation loss: 1.393277 \ttrain loss: 1.013397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:09<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: \tvalidation acc: 50.111607 \tvalidation loss: 1.415109 \ttrain loss: 1.017939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 32.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: \tvalidation acc: 47.321429 \tvalidation loss: 1.422517 \ttrain loss: 1.008723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: \tvalidation acc: 47.991071 \tvalidation loss: 1.433674 \ttrain loss: 0.985367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: \tvalidation acc: 47.879464 \tvalidation loss: 1.364570 \ttrain loss: 1.002001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: \tvalidation acc: 46.986607 \tvalidation loss: 1.460430 \ttrain loss: 0.986638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: \tvalidation acc: 48.214286 \tvalidation loss: 1.472376 \ttrain loss: 0.972459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \tvalidation acc: 48.995536 \tvalidation loss: 1.455708 \ttrain loss: 0.969186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: \tvalidation acc: 50.223214 \tvalidation loss: 1.419258 \ttrain loss: 0.972481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: \tvalidation acc: 48.772321 \tvalidation loss: 1.441947 \ttrain loss: 0.960537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: \tvalidation acc: 49.888393 \tvalidation loss: 1.427149 \ttrain loss: 0.957497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: \tvalidation acc: 49.330357 \tvalidation loss: 1.411207 \ttrain loss: 0.952882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: \tvalidation acc: 48.995536 \tvalidation loss: 1.460620 \ttrain loss: 0.934741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: \tvalidation acc: 50.334821 \tvalidation loss: 1.459701 \ttrain loss: 0.927482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: \tvalidation acc: 49.553571 \tvalidation loss: 1.412975 \ttrain loss: 0.924820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: \tvalidation acc: 49.218750 \tvalidation loss: 1.451184 \ttrain loss: 0.922705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: \tvalidation acc: 50.111607 \tvalidation loss: 1.437754 \ttrain loss: 0.926365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: \tvalidation acc: 50.446429 \tvalidation loss: 1.398488 \ttrain loss: 0.919037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: \tvalidation acc: 50.558036 \tvalidation loss: 1.452030 \ttrain loss: 0.908887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: \tvalidation acc: 50.111607 \tvalidation loss: 1.463083 \ttrain loss: 0.893743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: \tvalidation acc: 51.004464 \tvalidation loss: 1.410138 \ttrain loss: 0.913540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: \tvalidation acc: 51.116071 \tvalidation loss: 1.459836 \ttrain loss: 0.913259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: \tvalidation acc: 50.781250 \tvalidation loss: 1.470265 \ttrain loss: 0.905666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: \tvalidation acc: 50.000000 \tvalidation loss: 1.466918 \ttrain loss: 0.905153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: \tvalidation acc: 50.669643 \tvalidation loss: 1.429867 \ttrain loss: 0.885547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: \tvalidation acc: 51.227679 \tvalidation loss: 1.468752 \ttrain loss: 0.910102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 37.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: \tvalidation acc: 50.223214 \tvalidation loss: 1.435399 \ttrain loss: 0.885019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: \tvalidation acc: 52.455357 \tvalidation loss: 1.418295 \ttrain loss: 0.894931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: \tvalidation acc: 51.897321 \tvalidation loss: 1.371413 \ttrain loss: 0.893543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: \tvalidation acc: 52.790179 \tvalidation loss: 1.443166 \ttrain loss: 0.878307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: \tvalidation acc: 50.669643 \tvalidation loss: 1.438298 \ttrain loss: 0.888312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: \tvalidation acc: 50.000000 \tvalidation loss: 1.431482 \ttrain loss: 0.873150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: \tvalidation acc: 51.562500 \tvalidation loss: 1.431815 \ttrain loss: 0.883497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: \tvalidation acc: 50.781250 \tvalidation loss: 1.471541 \ttrain loss: 0.876538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: \tvalidation acc: 50.446429 \tvalidation loss: 1.452757 \ttrain loss: 0.864705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: \tvalidation acc: 52.008929 \tvalidation loss: 1.439598 \ttrain loss: 0.872834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:06<00:00, 35.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: \tvalidation acc: 53.348214 \tvalidation loss: 1.448777 \ttrain loss: 0.865621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bciiv2a_EEGNet, bciiv2a_data = bciiv2a(EEGNet, epochs=49, Reptile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-shot accuracy on subject 2: \tmean: 47.743056%\tstd: 12.513255%\n",
      "0-shot accuracy on subject 3: \tmean: 75.173611%\tstd: 12.367888%\n",
      "0-shot accuracy on subject 4: \tmean: 60.243056%\tstd: 12.071904%\n",
      "0-shot accuracy on subject 5: \tmean: 48.958333%\tstd: 9.140588%\n",
      "0-shot accuracy on subject 6: \tmean: 57.638889%\tstd: 11.795339%\n",
      "0-shot accuracy on subject 7: \tmean: 67.187500%\tstd: 10.031958%\n",
      "0-shot accuracy on subject 8: \tmean: 74.652778%\tstd: 10.819748%\n",
      "0-shot accuracy on subject 9: \tmean: 77.430556%\tstd: 9.912571%\n"
     ]
    }
   ],
   "source": [
    "evaluate0(bciiv2a_EEGNet, bciiv2a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-shot accuracy: \tmean: 63.541667%\tstd: 11.646187%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [07:38<00:00,  6.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-shot accuracy: \tmean: 60.714286%\tstd: 13.555559%\tafter 125 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [10:14<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-shot accuracy: \tmean: 64.322917%\tstd: 10.746724%\tafter 61 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [12:22<00:00, 10.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-shot accuracy: \tmean: 66.875000%\tstd: 9.291293%\tafter 101 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [09:51<00:00,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-shot accuracy: \tmean: 68.750000%\tstd: 11.410887%\tafter 77 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [11:08<00:00,  9.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-shot accuracy: \tmean: 69.531250%\tstd: 12.278308%\tafter 65 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [11:31<00:00,  9.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-shot accuracy: \tmean: 69.196429%\tstd: 8.984202%\tafter 123 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [12:31<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-shot accuracy: \tmean: 70.192308%\tstd: 12.294915%\tafter 65 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [13:51<00:00, 11.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-shot accuracy: \tmean: 71.354167%\tstd: 9.702050%\tafter 113 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [17:40<00:00, 14.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9-shot accuracy: \tmean: 73.863636%\tstd: 9.906589%\tafter 73 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [17:22<00:00, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-shot accuracy: \tmean: 72.500000%\tstd: 10.532687%\tafter 77 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_bciiv2a_EEGNet = evaluate(bciiv2a_EEGNet, bciiv2a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 \tfinetune acc:21.250000 \t\ttest acc:41.666667\n",
      "episode: 50 \tfinetune acc:41.250000 \t\ttest acc:56.250000\n",
      "episode: 100 \tfinetune acc:46.250000 \t\ttest acc:54.166667\n",
      "episode: 150 \tfinetune acc:50.000000 \t\ttest acc:45.833333\n",
      "episode: 200 \tfinetune acc:51.250000 \t\ttest acc:70.833333\n",
      "episode: 250 \tfinetune acc:42.500000 \t\ttest acc:52.083333\n",
      "episode: 300 \tfinetune acc:53.750000 \t\ttest acc:70.833333\n",
      "episode: 350 \tfinetune acc:42.500000 \t\ttest acc:66.666667\n",
      "episode: 400 \tfinetune acc:48.750000 \t\ttest acc:64.583333\n",
      "episode: 450 \tfinetune acc:60.000000 \t\ttest acc:64.583333\n",
      "episode: 500 \tfinetune acc:56.250000 \t\ttest acc:62.500000\n",
      "episode: 550 \tfinetune acc:60.000000 \t\ttest acc:60.416667\n",
      "episode: 600 \tfinetune acc:48.750000 \t\ttest acc:64.583333\n",
      "episode: 650 \tfinetune acc:55.000000 \t\ttest acc:52.083333\n",
      "episode: 700 \tfinetune acc:35.000000 \t\ttest acc:54.166667\n",
      "episode: 750 \tfinetune acc:60.000000 \t\ttest acc:56.250000\n",
      "episode: 800 \tfinetune acc:55.000000 \t\ttest acc:47.916667\n",
      "episode: 850 \tfinetune acc:65.000000 \t\ttest acc:58.333333\n",
      "episode: 900 \tfinetune acc:61.250000 \t\ttest acc:60.416667\n",
      "episode: 950 \tfinetune acc:68.750000 \t\ttest acc:43.750000\n",
      "episode: 1000 \tfinetune acc:57.500000 \t\ttest acc:62.500000\n",
      "episode: 1050 \tfinetune acc:50.000000 \t\ttest acc:60.416667\n",
      "episode: 1100 \tfinetune acc:61.250000 \t\ttest acc:41.666667\n",
      "episode: 1150 \tfinetune acc:45.000000 \t\ttest acc:66.666667\n",
      "episode: 1200 \tfinetune acc:57.500000 \t\ttest acc:68.750000\n",
      "episode: 1250 \tfinetune acc:57.500000 \t\ttest acc:66.666667\n",
      "episode: 1300 \tfinetune acc:61.250000 \t\ttest acc:60.416667\n",
      "episode: 1350 \tfinetune acc:55.000000 \t\ttest acc:50.000000\n",
      "episode: 1400 \tfinetune acc:65.000000 \t\ttest acc:68.750000\n",
      "episode: 1450 \tfinetune acc:61.250000 \t\ttest acc:66.666667\n",
      "episode: 1500 \tfinetune acc:52.500000 \t\ttest acc:64.583333\n",
      "episode: 1550 \tfinetune acc:53.750000 \t\ttest acc:64.583333\n",
      "episode: 1600 \tfinetune acc:57.500000 \t\ttest acc:72.916667\n",
      "episode: 1650 \tfinetune acc:51.250000 \t\ttest acc:64.583333\n",
      "episode: 1700 \tfinetune acc:66.250000 \t\ttest acc:68.750000\n",
      "episode: 1750 \tfinetune acc:56.250000 \t\ttest acc:58.333333\n",
      "episode: 1800 \tfinetune acc:62.500000 \t\ttest acc:58.333333\n",
      "episode: 1850 \tfinetune acc:61.250000 \t\ttest acc:68.750000\n",
      "episode: 1900 \tfinetune acc:63.750000 \t\ttest acc:54.166667\n",
      "episode: 1950 \tfinetune acc:56.250000 \t\ttest acc:66.666667\n",
      "episode: 2000 \tfinetune acc:70.000000 \t\ttest acc:58.333333\n",
      "episode: 2050 \tfinetune acc:70.000000 \t\ttest acc:68.750000\n",
      "episode: 2100 \tfinetune acc:58.750000 \t\ttest acc:72.916667\n",
      "episode: 2150 \tfinetune acc:46.250000 \t\ttest acc:70.833333\n",
      "episode: 2200 \tfinetune acc:60.000000 \t\ttest acc:62.500000\n",
      "episode: 2250 \tfinetune acc:58.750000 \t\ttest acc:72.916667\n",
      "episode: 2300 \tfinetune acc:60.000000 \t\ttest acc:58.333333\n",
      "episode: 2350 \tfinetune acc:50.000000 \t\ttest acc:58.333333\n",
      "episode: 2400 \tfinetune acc:56.250000 \t\ttest acc:60.416667\n",
      "episode: 2450 \tfinetune acc:52.500000 \t\ttest acc:58.333333\n",
      "episode: 2500 \tfinetune acc:60.000000 \t\ttest acc:72.916667\n",
      "episode: 2550 \tfinetune acc:62.500000 \t\ttest acc:62.500000\n",
      "episode: 2600 \tfinetune acc:66.250000 \t\ttest acc:47.916667\n",
      "episode: 2650 \tfinetune acc:65.000000 \t\ttest acc:60.416667\n",
      "episode: 2700 \tfinetune acc:60.000000 \t\ttest acc:60.416667\n",
      "episode: 2750 \tfinetune acc:63.750000 \t\ttest acc:70.833333\n",
      "episode: 2800 \tfinetune acc:63.750000 \t\ttest acc:66.666667\n",
      "episode: 2850 \tfinetune acc:55.000000 \t\ttest acc:72.916667\n",
      "episode: 2900 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
      "episode: 2950 \tfinetune acc:63.750000 \t\ttest acc:60.416667\n",
      "episode: 3000 \tfinetune acc:61.250000 \t\ttest acc:68.750000\n",
      "episode: 3050 \tfinetune acc:61.250000 \t\ttest acc:68.750000\n",
      "episode: 3100 \tfinetune acc:63.750000 \t\ttest acc:72.916667\n",
      "episode: 3150 \tfinetune acc:63.750000 \t\ttest acc:47.916667\n",
      "episode: 3200 \tfinetune acc:71.250000 \t\ttest acc:58.333333\n",
      "episode: 3250 \tfinetune acc:63.750000 \t\ttest acc:68.750000\n",
      "episode: 3300 \tfinetune acc:58.750000 \t\ttest acc:56.250000\n",
      "episode: 3350 \tfinetune acc:58.750000 \t\ttest acc:66.666667\n",
      "episode: 3400 \tfinetune acc:57.500000 \t\ttest acc:58.333333\n",
      "episode: 3450 \tfinetune acc:65.000000 \t\ttest acc:60.416667\n",
      "episode: 3500 \tfinetune acc:56.250000 \t\ttest acc:62.500000\n",
      "episode: 3550 \tfinetune acc:62.500000 \t\ttest acc:58.333333\n",
      "episode: 3600 \tfinetune acc:67.500000 \t\ttest acc:70.833333\n",
      "episode: 3650 \tfinetune acc:53.750000 \t\ttest acc:60.416667\n",
      "episode: 3700 \tfinetune acc:66.250000 \t\ttest acc:72.916667\n",
      "episode: 3750 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
      "episode: 3800 \tfinetune acc:68.750000 \t\ttest acc:70.833333\n",
      "episode: 3850 \tfinetune acc:63.750000 \t\ttest acc:52.083333\n",
      "episode: 3900 \tfinetune acc:68.750000 \t\ttest acc:54.166667\n",
      "episode: 3950 \tfinetune acc:51.250000 \t\ttest acc:58.333333\n",
      "episode: 4000 \tfinetune acc:57.500000 \t\ttest acc:66.666667\n",
      "episode: 4050 \tfinetune acc:73.750000 \t\ttest acc:70.833333\n",
      "episode: 4100 \tfinetune acc:66.250000 \t\ttest acc:70.833333\n",
      "episode: 4150 \tfinetune acc:71.250000 \t\ttest acc:54.166667\n",
      "episode: 4200 \tfinetune acc:68.750000 \t\ttest acc:64.583333\n",
      "episode: 4250 \tfinetune acc:62.500000 \t\ttest acc:60.416667\n",
      "episode: 4300 \tfinetune acc:68.750000 \t\ttest acc:56.250000\n",
      "episode: 4350 \tfinetune acc:62.500000 \t\ttest acc:85.416667\n",
      "episode: 4400 \tfinetune acc:70.000000 \t\ttest acc:66.666667\n",
      "episode: 4450 \tfinetune acc:58.750000 \t\ttest acc:60.416667\n",
      "episode: 4500 \tfinetune acc:66.250000 \t\ttest acc:62.500000\n",
      "episode: 4550 \tfinetune acc:52.500000 \t\ttest acc:56.250000\n",
      "episode: 4600 \tfinetune acc:66.250000 \t\ttest acc:68.750000\n",
      "episode: 4650 \tfinetune acc:73.750000 \t\ttest acc:64.583333\n",
      "episode: 4700 \tfinetune acc:58.750000 \t\ttest acc:70.833333\n",
      "episode: 4750 \tfinetune acc:65.000000 \t\ttest acc:58.333333\n",
      "episode: 4800 \tfinetune acc:70.000000 \t\ttest acc:52.083333\n",
      "episode: 4850 \tfinetune acc:77.500000 \t\ttest acc:62.500000\n",
      "episode: 4900 \tfinetune acc:73.750000 \t\ttest acc:79.166667\n",
      "episode: 4950 \tfinetune acc:66.250000 \t\ttest acc:58.333333\n",
      "episode: 5000 \tfinetune acc:76.250000 \t\ttest acc:65.625000\n",
      "episode: 5050 \tfinetune acc:77.500000 \t\ttest acc:67.187500\n",
      "episode: 5100 \tfinetune acc:63.750000 \t\ttest acc:71.875000\n",
      "episode: 5150 \tfinetune acc:58.750000 \t\ttest acc:68.750000\n",
      "episode: 5200 \tfinetune acc:70.000000 \t\ttest acc:65.625000\n",
      "episode: 5250 \tfinetune acc:60.000000 \t\ttest acc:65.625000\n",
      "episode: 5300 \tfinetune acc:60.000000 \t\ttest acc:57.812500\n",
      "episode: 5350 \tfinetune acc:65.000000 \t\ttest acc:71.875000\n",
      "episode: 5400 \tfinetune acc:71.250000 \t\ttest acc:57.812500\n",
      "episode: 5450 \tfinetune acc:70.000000 \t\ttest acc:64.062500\n",
      "episode: 5500 \tfinetune acc:70.000000 \t\ttest acc:64.062500\n",
      "episode: 5550 \tfinetune acc:63.750000 \t\ttest acc:56.250000\n",
      "episode: 5600 \tfinetune acc:61.250000 \t\ttest acc:70.312500\n",
      "episode: 5650 \tfinetune acc:58.750000 \t\ttest acc:60.937500\n",
      "episode: 5700 \tfinetune acc:85.000000 \t\ttest acc:67.187500\n",
      "episode: 5750 \tfinetune acc:58.750000 \t\ttest acc:62.500000\n",
      "episode: 5800 \tfinetune acc:55.000000 \t\ttest acc:70.312500\n",
      "episode: 5850 \tfinetune acc:71.250000 \t\ttest acc:56.250000\n",
      "episode: 5900 \tfinetune acc:67.500000 \t\ttest acc:53.125000\n",
      "episode: 5950 \tfinetune acc:77.500000 \t\ttest acc:57.812500\n",
      "episode: 6000 \tfinetune acc:68.750000 \t\ttest acc:56.250000\n",
      "episode: 6050 \tfinetune acc:46.250000 \t\ttest acc:68.750000\n",
      "episode: 6100 \tfinetune acc:72.500000 \t\ttest acc:68.750000\n",
      "episode: 6150 \tfinetune acc:72.500000 \t\ttest acc:59.375000\n",
      "episode: 6200 \tfinetune acc:71.250000 \t\ttest acc:51.562500\n",
      "episode: 6250 \tfinetune acc:65.000000 \t\ttest acc:62.500000\n",
      "episode: 6300 \tfinetune acc:51.250000 \t\ttest acc:70.312500\n",
      "episode: 6350 \tfinetune acc:68.750000 \t\ttest acc:68.750000\n",
      "episode: 6400 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
      "episode: 6450 \tfinetune acc:65.000000 \t\ttest acc:73.437500\n",
      "episode: 6500 \tfinetune acc:53.750000 \t\ttest acc:64.062500\n",
      "episode: 6550 \tfinetune acc:75.000000 \t\ttest acc:57.812500\n",
      "episode: 6600 \tfinetune acc:70.000000 \t\ttest acc:67.187500\n",
      "episode: 6650 \tfinetune acc:62.500000 \t\ttest acc:64.062500\n",
      "episode: 6700 \tfinetune acc:51.250000 \t\ttest acc:70.312500\n",
      "episode: 6750 \tfinetune acc:60.000000 \t\ttest acc:68.750000\n",
      "episode: 6800 \tfinetune acc:63.750000 \t\ttest acc:60.937500\n",
      "episode: 6850 \tfinetune acc:68.750000 \t\ttest acc:57.812500\n",
      "episode: 6900 \tfinetune acc:65.000000 \t\ttest acc:65.625000\n",
      "episode: 6950 \tfinetune acc:65.000000 \t\ttest acc:64.062500\n",
      "episode: 7000 \tfinetune acc:66.250000 \t\ttest acc:75.000000\n",
      "episode: 7050 \tfinetune acc:72.500000 \t\ttest acc:70.312500\n",
      "episode: 7100 \tfinetune acc:61.250000 \t\ttest acc:67.187500\n",
      "episode: 7150 \tfinetune acc:68.750000 \t\ttest acc:70.312500\n",
      "episode: 7200 \tfinetune acc:72.500000 \t\ttest acc:62.500000\n",
      "episode: 7250 \tfinetune acc:80.000000 \t\ttest acc:67.187500\n",
      "episode: 7300 \tfinetune acc:61.250000 \t\ttest acc:57.812500\n",
      "episode: 7350 \tfinetune acc:73.750000 \t\ttest acc:64.062500\n",
      "episode: 7400 \tfinetune acc:62.500000 \t\ttest acc:68.750000\n",
      "episode: 7450 \tfinetune acc:65.000000 \t\ttest acc:65.625000\n",
      "episode: 7500 \tfinetune acc:81.250000 \t\ttest acc:65.625000\n",
      "episode: 7550 \tfinetune acc:70.000000 \t\ttest acc:51.562500\n",
      "episode: 7600 \tfinetune acc:62.500000 \t\ttest acc:64.062500\n",
      "episode: 7650 \tfinetune acc:62.500000 \t\ttest acc:56.250000\n",
      "episode: 7700 \tfinetune acc:71.250000 \t\ttest acc:62.500000\n",
      "episode: 7750 \tfinetune acc:66.250000 \t\ttest acc:65.625000\n",
      "episode: 7800 \tfinetune acc:62.500000 \t\ttest acc:67.187500\n",
      "episode: 7850 \tfinetune acc:65.000000 \t\ttest acc:62.500000\n",
      "episode: 7900 \tfinetune acc:62.500000 \t\ttest acc:57.812500\n",
      "episode: 7950 \tfinetune acc:78.750000 \t\ttest acc:57.812500\n",
      "episode: 8000 \tfinetune acc:70.000000 \t\ttest acc:64.062500\n",
      "episode: 8050 \tfinetune acc:67.500000 \t\ttest acc:64.062500\n",
      "episode: 8100 \tfinetune acc:61.250000 \t\ttest acc:53.125000\n",
      "episode: 8150 \tfinetune acc:57.500000 \t\ttest acc:73.437500\n",
      "episode: 8200 \tfinetune acc:72.500000 \t\ttest acc:64.062500\n",
      "episode: 8250 \tfinetune acc:78.750000 \t\ttest acc:60.937500\n",
      "episode: 8300 \tfinetune acc:73.750000 \t\ttest acc:60.937500\n",
      "episode: 8350 \tfinetune acc:68.750000 \t\ttest acc:59.375000\n",
      "episode: 8400 \tfinetune acc:75.000000 \t\ttest acc:64.062500\n",
      "episode: 8450 \tfinetune acc:68.750000 \t\ttest acc:67.187500\n",
      "episode: 8500 \tfinetune acc:70.000000 \t\ttest acc:59.375000\n",
      "episode: 8550 \tfinetune acc:62.500000 \t\ttest acc:67.187500\n",
      "episode: 8600 \tfinetune acc:56.250000 \t\ttest acc:71.875000\n",
      "episode: 8650 \tfinetune acc:68.750000 \t\ttest acc:67.187500\n",
      "episode: 8700 \tfinetune acc:65.000000 \t\ttest acc:73.437500\n",
      "episode: 8750 \tfinetune acc:63.750000 \t\ttest acc:65.625000\n",
      "episode: 8800 \tfinetune acc:78.750000 \t\ttest acc:65.625000\n",
      "episode: 8850 \tfinetune acc:67.500000 \t\ttest acc:67.187500\n",
      "episode: 8900 \tfinetune acc:73.750000 \t\ttest acc:73.437500\n",
      "episode: 8950 \tfinetune acc:61.250000 \t\ttest acc:71.875000\n",
      "episode: 9000 \tfinetune acc:70.000000 \t\ttest acc:64.062500\n",
      "episode: 9050 \tfinetune acc:65.000000 \t\ttest acc:65.625000\n",
      "episode: 9100 \tfinetune acc:66.250000 \t\ttest acc:60.937500\n",
      "episode: 9150 \tfinetune acc:68.750000 \t\ttest acc:71.875000\n",
      "episode: 9200 \tfinetune acc:68.750000 \t\ttest acc:57.812500\n",
      "episode: 9250 \tfinetune acc:75.000000 \t\ttest acc:68.750000\n",
      "episode: 9300 \tfinetune acc:60.000000 \t\ttest acc:65.625000\n",
      "episode: 9350 \tfinetune acc:78.750000 \t\ttest acc:68.750000\n",
      "episode: 9400 \tfinetune acc:72.500000 \t\ttest acc:56.250000\n",
      "episode: 9450 \tfinetune acc:65.000000 \t\ttest acc:65.625000\n",
      "episode: 9500 \tfinetune acc:77.500000 \t\ttest acc:64.062500\n",
      "episode: 9550 \tfinetune acc:53.750000 \t\ttest acc:70.312500\n",
      "episode: 9600 \tfinetune acc:56.250000 \t\ttest acc:64.062500\n",
      "episode: 9650 \tfinetune acc:66.250000 \t\ttest acc:59.375000\n",
      "episode: 9700 \tfinetune acc:68.750000 \t\ttest acc:65.625000\n",
      "episode: 9750 \tfinetune acc:77.500000 \t\ttest acc:59.375000\n",
      "episode: 9800 \tfinetune acc:65.000000 \t\ttest acc:64.062500\n",
      "episode: 9850 \tfinetune acc:66.250000 \t\ttest acc:62.500000\n",
      "episode: 9900 \tfinetune acc:70.000000 \t\ttest acc:68.750000\n",
      "episode: 9950 \tfinetune acc:67.500000 \t\ttest acc:68.750000\n",
      "episode: 10000 \tfinetune acc:76.250000 \t\ttest acc:65.000000\n",
      "episode: 10050 \tfinetune acc:72.500000 \t\ttest acc:58.750000\n",
      "episode: 10100 \tfinetune acc:66.250000 \t\ttest acc:68.750000\n",
      "episode: 10150 \tfinetune acc:71.250000 \t\ttest acc:76.250000\n",
      "episode: 10200 \tfinetune acc:67.500000 \t\ttest acc:62.500000\n",
      "episode: 10250 \tfinetune acc:58.750000 \t\ttest acc:62.500000\n",
      "episode: 10300 \tfinetune acc:70.000000 \t\ttest acc:55.000000\n",
      "episode: 10350 \tfinetune acc:70.000000 \t\ttest acc:60.000000\n",
      "episode: 10400 \tfinetune acc:63.750000 \t\ttest acc:60.000000\n",
      "episode: 10450 \tfinetune acc:68.750000 \t\ttest acc:66.250000\n",
      "episode: 10500 \tfinetune acc:70.000000 \t\ttest acc:73.750000\n",
      "episode: 10550 \tfinetune acc:66.250000 \t\ttest acc:61.250000\n",
      "episode: 10600 \tfinetune acc:62.500000 \t\ttest acc:66.250000\n",
      "episode: 10650 \tfinetune acc:60.000000 \t\ttest acc:62.500000\n",
      "episode: 10700 \tfinetune acc:75.000000 \t\ttest acc:57.500000\n",
      "episode: 10750 \tfinetune acc:67.500000 \t\ttest acc:67.500000\n",
      "episode: 10800 \tfinetune acc:62.500000 \t\ttest acc:73.750000\n",
      "episode: 10850 \tfinetune acc:70.000000 \t\ttest acc:71.250000\n",
      "episode: 10900 \tfinetune acc:63.750000 \t\ttest acc:57.500000\n",
      "episode: 10950 \tfinetune acc:75.000000 \t\ttest acc:66.250000\n",
      "episode: 11000 \tfinetune acc:57.500000 \t\ttest acc:63.750000\n",
      "episode: 11050 \tfinetune acc:60.000000 \t\ttest acc:65.000000\n",
      "episode: 11100 \tfinetune acc:66.250000 \t\ttest acc:61.250000\n",
      "episode: 11150 \tfinetune acc:68.750000 \t\ttest acc:62.500000\n",
      "episode: 11200 \tfinetune acc:71.250000 \t\ttest acc:65.000000\n",
      "episode: 11250 \tfinetune acc:67.500000 \t\ttest acc:63.750000\n",
      "episode: 11300 \tfinetune acc:71.250000 \t\ttest acc:62.500000\n",
      "episode: 11350 \tfinetune acc:63.750000 \t\ttest acc:58.750000\n",
      "episode: 11400 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
      "episode: 11450 \tfinetune acc:65.000000 \t\ttest acc:63.750000\n",
      "episode: 11500 \tfinetune acc:73.750000 \t\ttest acc:63.750000\n",
      "episode: 11550 \tfinetune acc:80.000000 \t\ttest acc:67.500000\n",
      "episode: 11600 \tfinetune acc:65.000000 \t\ttest acc:57.500000\n",
      "episode: 11650 \tfinetune acc:76.250000 \t\ttest acc:68.750000\n",
      "episode: 11700 \tfinetune acc:76.250000 \t\ttest acc:71.250000\n",
      "episode: 11750 \tfinetune acc:77.500000 \t\ttest acc:60.000000\n",
      "episode: 11800 \tfinetune acc:68.750000 \t\ttest acc:65.000000\n",
      "episode: 11850 \tfinetune acc:76.250000 \t\ttest acc:66.250000\n",
      "episode: 11900 \tfinetune acc:70.000000 \t\ttest acc:57.500000\n",
      "episode: 11950 \tfinetune acc:67.500000 \t\ttest acc:67.500000\n",
      "episode: 12000 \tfinetune acc:67.500000 \t\ttest acc:58.750000\n",
      "episode: 12050 \tfinetune acc:67.500000 \t\ttest acc:56.250000\n",
      "episode: 12100 \tfinetune acc:66.250000 \t\ttest acc:65.000000\n",
      "episode: 12150 \tfinetune acc:75.000000 \t\ttest acc:76.250000\n",
      "episode: 12200 \tfinetune acc:63.750000 \t\ttest acc:71.250000\n",
      "episode: 12250 \tfinetune acc:70.000000 \t\ttest acc:60.000000\n",
      "episode: 12300 \tfinetune acc:73.750000 \t\ttest acc:60.000000\n",
      "episode: 12350 \tfinetune acc:71.250000 \t\ttest acc:65.000000\n",
      "episode: 12400 \tfinetune acc:63.750000 \t\ttest acc:58.750000\n",
      "episode: 12450 \tfinetune acc:52.500000 \t\ttest acc:56.250000\n",
      "episode: 12500 \tfinetune acc:71.250000 \t\ttest acc:62.500000\n",
      "episode: 12550 \tfinetune acc:70.000000 \t\ttest acc:71.250000\n",
      "episode: 12600 \tfinetune acc:73.750000 \t\ttest acc:71.250000\n",
      "episode: 12650 \tfinetune acc:62.500000 \t\ttest acc:70.000000\n",
      "episode: 12700 \tfinetune acc:72.500000 \t\ttest acc:67.500000\n",
      "episode: 12750 \tfinetune acc:62.500000 \t\ttest acc:62.500000\n",
      "episode: 12800 \tfinetune acc:65.000000 \t\ttest acc:57.500000\n",
      "episode: 12850 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
      "episode: 12900 \tfinetune acc:77.500000 \t\ttest acc:71.250000\n",
      "episode: 12950 \tfinetune acc:81.250000 \t\ttest acc:63.750000\n",
      "episode: 13000 \tfinetune acc:65.000000 \t\ttest acc:61.250000\n",
      "episode: 13050 \tfinetune acc:73.750000 \t\ttest acc:72.500000\n",
      "episode: 13100 \tfinetune acc:76.250000 \t\ttest acc:60.000000\n",
      "episode: 13150 \tfinetune acc:65.000000 \t\ttest acc:58.750000\n",
      "episode: 13200 \tfinetune acc:76.250000 \t\ttest acc:58.750000\n",
      "episode: 13250 \tfinetune acc:80.000000 \t\ttest acc:58.750000\n",
      "episode: 13300 \tfinetune acc:66.250000 \t\ttest acc:61.250000\n",
      "episode: 13350 \tfinetune acc:67.500000 \t\ttest acc:62.500000\n",
      "episode: 13400 \tfinetune acc:73.750000 \t\ttest acc:67.500000\n",
      "episode: 13450 \tfinetune acc:72.500000 \t\ttest acc:66.250000\n",
      "episode: 13500 \tfinetune acc:65.000000 \t\ttest acc:66.250000\n",
      "episode: 13550 \tfinetune acc:77.500000 \t\ttest acc:72.500000\n",
      "episode: 13600 \tfinetune acc:71.250000 \t\ttest acc:63.750000\n",
      "episode: 13650 \tfinetune acc:76.250000 \t\ttest acc:68.750000\n",
      "episode: 13700 \tfinetune acc:68.750000 \t\ttest acc:65.000000\n",
      "episode: 13750 \tfinetune acc:76.250000 \t\ttest acc:67.500000\n",
      "episode: 13800 \tfinetune acc:72.500000 \t\ttest acc:61.250000\n",
      "episode: 13850 \tfinetune acc:62.500000 \t\ttest acc:68.750000\n",
      "episode: 13900 \tfinetune acc:70.000000 \t\ttest acc:70.000000\n",
      "episode: 13950 \tfinetune acc:76.250000 \t\ttest acc:56.250000\n",
      "episode: 14000 \tfinetune acc:65.000000 \t\ttest acc:63.750000\n",
      "episode: 14050 \tfinetune acc:62.500000 \t\ttest acc:58.750000\n",
      "episode: 14100 \tfinetune acc:68.750000 \t\ttest acc:61.250000\n",
      "episode: 14150 \tfinetune acc:80.000000 \t\ttest acc:60.000000\n",
      "episode: 14200 \tfinetune acc:67.500000 \t\ttest acc:71.250000\n",
      "episode: 14250 \tfinetune acc:62.500000 \t\ttest acc:66.250000\n",
      "episode: 14300 \tfinetune acc:52.500000 \t\ttest acc:67.500000\n",
      "episode: 14350 \tfinetune acc:73.750000 \t\ttest acc:58.750000\n",
      "episode: 14400 \tfinetune acc:71.250000 \t\ttest acc:71.250000\n",
      "episode: 14450 \tfinetune acc:76.250000 \t\ttest acc:62.500000\n",
      "episode: 14500 \tfinetune acc:75.000000 \t\ttest acc:65.000000\n",
      "episode: 14550 \tfinetune acc:68.750000 \t\ttest acc:55.000000\n",
      "episode: 14600 \tfinetune acc:65.000000 \t\ttest acc:66.250000\n",
      "episode: 14650 \tfinetune acc:61.250000 \t\ttest acc:56.250000\n",
      "episode: 14700 \tfinetune acc:72.500000 \t\ttest acc:63.750000\n",
      "episode: 14750 \tfinetune acc:70.000000 \t\ttest acc:68.750000\n",
      "episode: 14800 \tfinetune acc:67.500000 \t\ttest acc:61.250000\n",
      "episode: 14850 \tfinetune acc:70.000000 \t\ttest acc:66.250000\n",
      "episode: 14900 \tfinetune acc:77.500000 \t\ttest acc:58.750000\n",
      "episode: 14950 \tfinetune acc:73.750000 \t\ttest acc:66.250000\n",
      "episode: 15000 \tfinetune acc:72.500000 \t\ttest acc:78.125000\n",
      "episode: 15050 \tfinetune acc:61.250000 \t\ttest acc:63.541667\n",
      "episode: 15100 \tfinetune acc:66.250000 \t\ttest acc:68.750000\n",
      "episode: 15150 \tfinetune acc:68.750000 \t\ttest acc:59.375000\n",
      "episode: 15200 \tfinetune acc:66.250000 \t\ttest acc:65.625000\n",
      "episode: 15250 \tfinetune acc:76.250000 \t\ttest acc:71.875000\n",
      "episode: 15300 \tfinetune acc:65.000000 \t\ttest acc:63.541667\n",
      "episode: 15350 \tfinetune acc:78.750000 \t\ttest acc:67.708333\n",
      "episode: 15400 \tfinetune acc:70.000000 \t\ttest acc:71.875000\n",
      "episode: 15450 \tfinetune acc:65.000000 \t\ttest acc:69.791667\n",
      "episode: 15500 \tfinetune acc:58.750000 \t\ttest acc:72.916667\n",
      "episode: 15550 \tfinetune acc:60.000000 \t\ttest acc:66.666667\n",
      "episode: 15600 \tfinetune acc:83.750000 \t\ttest acc:68.750000\n",
      "episode: 15650 \tfinetune acc:68.750000 \t\ttest acc:64.583333\n",
      "episode: 15700 \tfinetune acc:71.250000 \t\ttest acc:63.541667\n",
      "episode: 15750 \tfinetune acc:71.250000 \t\ttest acc:75.000000\n",
      "episode: 15800 \tfinetune acc:62.500000 \t\ttest acc:63.541667\n",
      "episode: 15850 \tfinetune acc:58.750000 \t\ttest acc:64.583333\n",
      "episode: 15900 \tfinetune acc:72.500000 \t\ttest acc:65.625000\n",
      "episode: 15950 \tfinetune acc:82.500000 \t\ttest acc:72.916667\n",
      "episode: 16000 \tfinetune acc:78.750000 \t\ttest acc:63.541667\n",
      "episode: 16050 \tfinetune acc:61.250000 \t\ttest acc:63.541667\n",
      "episode: 16100 \tfinetune acc:72.500000 \t\ttest acc:67.708333\n",
      "episode: 16150 \tfinetune acc:67.500000 \t\ttest acc:69.791667\n",
      "episode: 16200 \tfinetune acc:67.500000 \t\ttest acc:67.708333\n",
      "episode: 16250 \tfinetune acc:62.500000 \t\ttest acc:57.291667\n",
      "episode: 16300 \tfinetune acc:67.500000 \t\ttest acc:59.375000\n",
      "episode: 16350 \tfinetune acc:85.000000 \t\ttest acc:68.750000\n",
      "episode: 16400 \tfinetune acc:68.750000 \t\ttest acc:63.541667\n",
      "episode: 16450 \tfinetune acc:73.750000 \t\ttest acc:62.500000\n",
      "episode: 16500 \tfinetune acc:78.750000 \t\ttest acc:69.791667\n",
      "episode: 16550 \tfinetune acc:82.500000 \t\ttest acc:70.833333\n",
      "episode: 16600 \tfinetune acc:68.750000 \t\ttest acc:64.583333\n",
      "episode: 16650 \tfinetune acc:68.750000 \t\ttest acc:65.625000\n",
      "episode: 16700 \tfinetune acc:76.250000 \t\ttest acc:63.541667\n",
      "episode: 16750 \tfinetune acc:78.750000 \t\ttest acc:63.541667\n",
      "episode: 16800 \tfinetune acc:63.750000 \t\ttest acc:60.416667\n",
      "episode: 16850 \tfinetune acc:77.500000 \t\ttest acc:59.375000\n",
      "episode: 16900 \tfinetune acc:76.250000 \t\ttest acc:67.708333\n",
      "episode: 16950 \tfinetune acc:71.250000 \t\ttest acc:64.583333\n",
      "episode: 17000 \tfinetune acc:66.250000 \t\ttest acc:71.875000\n",
      "episode: 17050 \tfinetune acc:72.500000 \t\ttest acc:64.583333\n",
      "episode: 17100 \tfinetune acc:66.250000 \t\ttest acc:69.791667\n",
      "episode: 17150 \tfinetune acc:67.500000 \t\ttest acc:60.416667\n",
      "episode: 17200 \tfinetune acc:73.750000 \t\ttest acc:58.333333\n",
      "episode: 17250 \tfinetune acc:75.000000 \t\ttest acc:69.791667\n",
      "episode: 17300 \tfinetune acc:70.000000 \t\ttest acc:65.625000\n",
      "episode: 17350 \tfinetune acc:66.250000 \t\ttest acc:62.500000\n",
      "episode: 17400 \tfinetune acc:71.250000 \t\ttest acc:68.750000\n",
      "episode: 17450 \tfinetune acc:65.000000 \t\ttest acc:62.500000\n",
      "episode: 17500 \tfinetune acc:71.250000 \t\ttest acc:64.583333\n",
      "episode: 17550 \tfinetune acc:72.500000 \t\ttest acc:56.250000\n",
      "episode: 17600 \tfinetune acc:73.750000 \t\ttest acc:56.250000\n",
      "episode: 17650 \tfinetune acc:67.500000 \t\ttest acc:65.625000\n",
      "episode: 17700 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
      "episode: 17750 \tfinetune acc:72.500000 \t\ttest acc:67.708333\n",
      "episode: 17800 \tfinetune acc:70.000000 \t\ttest acc:58.333333\n",
      "episode: 17850 \tfinetune acc:66.250000 \t\ttest acc:58.333333\n",
      "episode: 17900 \tfinetune acc:73.750000 \t\ttest acc:67.708333\n",
      "episode: 17950 \tfinetune acc:68.750000 \t\ttest acc:58.333333\n",
      "episode: 18000 \tfinetune acc:73.750000 \t\ttest acc:63.541667\n",
      "episode: 18050 \tfinetune acc:70.000000 \t\ttest acc:52.083333\n",
      "episode: 18100 \tfinetune acc:76.250000 \t\ttest acc:66.666667\n",
      "episode: 18150 \tfinetune acc:73.750000 \t\ttest acc:63.541667\n",
      "episode: 18200 \tfinetune acc:61.250000 \t\ttest acc:65.625000\n",
      "episode: 18250 \tfinetune acc:73.750000 \t\ttest acc:65.625000\n",
      "episode: 18300 \tfinetune acc:70.000000 \t\ttest acc:60.416667\n",
      "episode: 18350 \tfinetune acc:76.250000 \t\ttest acc:68.750000\n",
      "episode: 18400 \tfinetune acc:61.250000 \t\ttest acc:65.625000\n",
      "episode: 18450 \tfinetune acc:71.250000 \t\ttest acc:62.500000\n",
      "episode: 18500 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
      "episode: 18550 \tfinetune acc:72.500000 \t\ttest acc:69.791667\n",
      "episode: 18600 \tfinetune acc:85.000000 \t\ttest acc:70.833333\n",
      "episode: 18650 \tfinetune acc:66.250000 \t\ttest acc:59.375000\n",
      "episode: 18700 \tfinetune acc:66.250000 \t\ttest acc:70.833333\n",
      "episode: 18750 \tfinetune acc:66.250000 \t\ttest acc:67.708333\n",
      "episode: 18800 \tfinetune acc:66.250000 \t\ttest acc:61.458333\n",
      "episode: 18850 \tfinetune acc:60.000000 \t\ttest acc:64.583333\n",
      "episode: 18900 \tfinetune acc:65.000000 \t\ttest acc:58.333333\n",
      "episode: 18950 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
      "episode: 19000 \tfinetune acc:75.000000 \t\ttest acc:70.833333\n",
      "episode: 19050 \tfinetune acc:78.750000 \t\ttest acc:66.666667\n",
      "episode: 19100 \tfinetune acc:82.500000 \t\ttest acc:66.666667\n",
      "episode: 19150 \tfinetune acc:68.750000 \t\ttest acc:64.583333\n",
      "episode: 19200 \tfinetune acc:73.750000 \t\ttest acc:71.875000\n",
      "episode: 19250 \tfinetune acc:70.000000 \t\ttest acc:61.458333\n",
      "episode: 19300 \tfinetune acc:77.500000 \t\ttest acc:66.666667\n",
      "episode: 19350 \tfinetune acc:73.750000 \t\ttest acc:70.833333\n",
      "episode: 19400 \tfinetune acc:61.250000 \t\ttest acc:71.875000\n",
      "episode: 19450 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
      "episode: 19500 \tfinetune acc:76.250000 \t\ttest acc:71.875000\n",
      "episode: 19550 \tfinetune acc:70.000000 \t\ttest acc:57.291667\n",
      "episode: 19600 \tfinetune acc:70.000000 \t\ttest acc:68.750000\n",
      "episode: 19650 \tfinetune acc:68.750000 \t\ttest acc:70.833333\n",
      "episode: 19700 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
      "episode: 19750 \tfinetune acc:72.500000 \t\ttest acc:70.833333\n",
      "episode: 19800 \tfinetune acc:67.500000 \t\ttest acc:59.375000\n",
      "episode: 19850 \tfinetune acc:73.750000 \t\ttest acc:64.583333\n",
      "episode: 19900 \tfinetune acc:75.000000 \t\ttest acc:63.541667\n",
      "episode: 19950 \tfinetune acc:67.500000 \t\ttest acc:58.333333\n"
     ]
    }
   ],
   "source": [
    "bciiv2a_EEGNet_Reptile, bciiv2a_data = bciiv2a(EEGNet, iterations=20000, Reptile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-shot accuracy on subject 2: \tmean: 52.604167%\tstd: 11.060813%\n",
      "0-shot accuracy on subject 3: \tmean: 84.201389%\tstd: 9.138939%\n",
      "0-shot accuracy on subject 4: \tmean: 67.361111%\tstd: 11.977909%\n",
      "0-shot accuracy on subject 5: \tmean: 59.548611%\tstd: 12.279842%\n",
      "0-shot accuracy on subject 6: \tmean: 59.375000%\tstd: 10.468620%\n",
      "0-shot accuracy on subject 7: \tmean: 80.034722%\tstd: 10.292958%\n",
      "0-shot accuracy on subject 8: \tmean: 80.034722%\tstd: 9.178430%\n",
      "0-shot accuracy on subject 9: \tmean: 78.993056%\tstd: 9.788650%\n"
     ]
    }
   ],
   "source": [
    "evaluate0(bciiv2a_EEGNet_Reptile, bciiv2a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-shot accuracy: \tmean: 70.833333%\tstd: 13.339842%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [07:09<00:00,  5.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-shot accuracy: \tmean: 64.955357%\tstd: 12.758410%\tafter 7 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [11:03<00:00,  9.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-shot accuracy: \tmean: 66.145833%\tstd: 11.956500%\tafter 59 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [12:03<00:00,  9.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-shot accuracy: \tmean: 69.062500%\tstd: 9.777805%\tafter 7 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [10:13<00:00,  8.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-shot accuracy: \tmean: 70.486111%\tstd: 9.034453%\tafter 35 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [10:51<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-shot accuracy: \tmean: 71.093750%\tstd: 11.240230%\tafter 133 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [11:26<00:00,  9.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-shot accuracy: \tmean: 73.214286%\tstd: 6.438484%\tafter 147 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [12:51<00:00, 10.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-shot accuracy: \tmean: 74.519231%\tstd: 11.618313%\tafter 143 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [14:11<00:00, 11.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-shot accuracy: \tmean: 73.958333%\tstd: 9.140588%\tafter 71 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [17:30<00:00, 14.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9-shot accuracy: \tmean: 75.000000%\tstd: 13.588933%\tafter 47 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [17:39<00:00, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-shot accuracy: \tmean: 76.250000%\tstd: 9.185587%\tafter 137 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_bciiv2a_EEGNet_Reptile = evaluate(bciiv2a_EEGNet_Reptile, bciiv2a_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
